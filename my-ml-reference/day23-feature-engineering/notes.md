Feature engineering is the process of using *domain knowledge* to extract features from raw data.

These features can be used to improve the performance of ML algorithms.

This is the Machine learning life cycle.


![](https://live.staticflickr.com/65535/54980433874_3206bfd4dc_b.jpg)

Feature engineering flowchart

![](https://live.staticflickr.com/65535/54979308632_a3b7df15dd_b.jpg)



## 1.1 Missing Value imputation

![](https://live.staticflickr.com/65535/54980443484_e433a3eb67_c.jpg)

## 1.2 Handling *categorical* values

![](https://live.staticflickr.com/65535/54979315787_4068a3dca9_c.jpg)

## 1.3 Outlier Detection

if outliers are not detected in removed accuracy gets highly affected.

![](https://live.staticflickr.com/65535/54980497565_2283be8359_c.jpg)


## 1.4 Feature scaling

Useful when the algo finds distance bw two points

since if values aren't popularly scaled

they impact the accuracy of the model a lot.

![](https://live.staticflickr.com/65535/54980470404_3a57362866_z.jpg)

Useful in regression and KNN

not useful in decision tree.

## 2. Feature construction --> based on domain knowledge and intuition

![](https://live.staticflickr.com/65535/54979344662_916e09a651_c.jpg)

this is manual and this is how it differs from feature extraction


## 3. Feature Selection

![](https://live.staticflickr.com/65535/54980413198_c3c481fd0e_c.jpg)

28*28 grid

so we select 20 pixels around 28 --> we eliminate 

## 4. Feature extraction

This is automatic

common in high dimensional data

example --> PCA

![](https://live.staticflickr.com/65535/54980537935_9516c17168.jpg)

we create new feature and remove older features.



